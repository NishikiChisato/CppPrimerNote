# 内存虚拟化

- [内存虚拟化](#内存虚拟化)
  - [概述](#概述)
  - [抽象：地址空间](#抽象地址空间)
  - [机制：地址转换](#机制地址转换)
  - [分段](#分段)
  - [分页](#分页)
    - [原理 \& 页表](#原理--页表)
    - [页表内容](#页表内容)
    - [分页速度](#分页速度)
  - [Translation-lookaside buffer (TLB)](#translation-lookaside-buffer-tlb)
    - [TLB Basic Algorithm](#tlb-basic-algorithm)

## 概述

用户程序所能看见的地址均为**虚拟地址**，应用程序所生成的地址也为虚拟地址。操作系统为每个进程提供一个**假象**，即每个进程都拥有**大量的私有内存**，而操作系统在硬件的帮助下会将这些虚拟地址变为真实的物理地址，这便是内存虚拟化

## 抽象：地址空间

处于交互性 `interativity` 的需要，操作系统需要实现**时分共享**，而最简单的办法是将一个进程占用全部内存运行一段时间，然后停止它并将其**所有的状态信息保存在磁盘上（包括所有的物理内存）**。但这样有一个问题是，运行的太慢了，仅仅是保存寄存器等状态信息的速度还相对较快，但保存所有的内存信息到磁盘就太慢了。因此操作系统在**执行进程切换时，仍将进程的信息保存在内存中**（此时我们讨论的内存为物理内存）

![Shareing memory](../img/Shareing%20memory.png)

如上图所示，每个进程都拥有**全部物理内存** $512kb$ 的一小部分，操作系统每次运行一个进程，而其余的进程则在队列当中进行等待（它们的状态信息依旧存储在内存中）

将所有的进程信息都存储在**物理内存**中，我们很难保证一个进程不会去修改另一个进程的信息，这便引出了隔离 `isolation` 和保护 `protection` 的问题

为了解决直接使用物理内存而导致的问题，操作系统会为所有的**进程**提供一层抽象，这个抽象称之为**地址空间 `address space` **，这便是**虚拟内存**的关键

我们引出了进程的地址空间这一抽象的概念，一个进程的地址空间必须包含该进程的所有内存状态：程序的代码 `code` 用来指示该程序该如何执行；栈 `stack` 用来保存当前函数的调用信息，为局部变量、传递参数、返回值所分配的空间；堆 `heap` 来存储动态分配的内存。因此在进程的地址空间中，我们需要存储这三种信息（当然还有静态初始化的变量，但我们这里不讨论这个）

![Address space](../img/Address%20space.png)

在一个只有 $16kb$ 的**地址空间**中，`code` 部分存放在从 $0$ 开始的地址处，`heap` 和 `stack` 分别向下和向上增长，二者的起始地址分别为 $1kb$ 和 $16kb$。当然，这里堆栈的放置方法只是一种约定，并不是所有的情况都是这样放置

需要说明的是，地址空间的 $0\sim 16kb$ 并不等于实际物理地址的 $0\sim 16kb$，而是被**加载到任意的实际地址空间中**，我们称该过程为内存虚拟化 `virtualizing memory`

> 补充：**所有用户级看到的地址都是虚拟地址**
> 
> C语言中指针的地址、甚至是程序所在的地址都是虚拟地址，因此我们**在汇编语言中所看到的地址也是虚拟地址**
>
> 这里或许会有一个矛盾，汇编语言中的栈指针 `%rsp` 是向低地址增长的，但程序的地址空间中的栈是向高地址增长的，二者不矛盾吗？
>
> 实际上是不矛盾的，首先 `%rsp` 肯定是在地址空间中栈的部分的，只不过这里的栈存储的是该进程所有需要保存在栈上的信息，因此这里实际上可以理解为，**每次函数调用都是在栈顶压入一大块空间（将该函数的栈帧压入）**，然后 **`%rsp` 在该空间内向下移动**
>
> 本质上，用户级程序以及程序员所看到的所有地址都是虚拟地址，这提供地址如何在物理内存中分布的假象，知道实际物理内存地址的只有操作系统和硬件
>
>---
>
> 补充：栈内存与堆内存
> 
> **栈内存的申请和释放由编译器来隐式管理**，因此也被称为自动 `automatic` 内存（所有的变量，函数调用时的函数栈帧等）。**堆内存的申请和释放则由程序员显式地完成**
>
> 由于堆内存不是由编译器自动管理的，便会容易产生申请了内存但没有释放的情况，这被称为**内存泄漏**（进程的堆空间存在无法使用的内存）
>
> 我们在此讨论的问题是，如果程序很快结束，使用 `malloc` 申请内存后不用 `free` 归还，为什么不会发生内存`丢失`
>
> 这里的原因是，**操作系统存在两级的内存管理**
> 
> 第一级是由操作系统所执行的，操作系统在进程执行时将内存空间交给进程，并在进程结束时（无论以何种方式结束）将内存回收；第二级是在每个进程中，进程可以独立管理自己地址空间内的虚拟内存。即使因为忘记使用 `free` 而泄露了堆中的内存，操作系统也会在程序退出时回收所有的空间（包括代码段和堆栈空间）。因此无论地址空间中堆的状态如何，都不会发生内存丢失的问题

---

## 机制：地址转换

我们假设进程的地址空间必须**连续的存储在内存当中**，地址空间**不是很大**，每个地址空间的**大小完全一样**。在后面的讨论中，我们会逐步放开这些限制，进而得到一个具有普适性的内存虚拟化模型

内存虚拟化的主要技术为地址转换 `address translation` ，全称为基于硬件的地址转换 `hardware-based address translation`。利用这种机制，**硬件**每次都会对内存访问进行处理（包括指令的读取、数据的读取和写入），将指令中的虚拟地址转换为实际的物理地址

这一层支持由硬件提供，而操作系统需要做的是管理内存 `manage memory`，记录占用和空闲的内存位置，保持对内存的控制。类似于 `CPU` 虚拟化，我们在内存虚拟化也会引入直接受限执行的概念，一般由硬件提供虚拟地址到物理地址转换的支持，而操作系统则会在合适的时候介入

那么这里便引出了一个问题：我们要将虚拟内存放到物理内存的什么地方

这时我们引入动态重定位的机制 `dynamic relocation`，也被称为基址和界限机制 `base and bound`

具体地，**每个 `CPU` 都需要两个「硬件」寄存器**：基址 `base` 寄存器和界限 `bound` 寄存器。利用这组基址和界限寄存器，地址空间便可以放在物理内存的任何位置，同时也能保证进程不会访问到其他的数据

我们总是假设虚拟地址空间从 $0$ 开始。当程序开始执行时，操作系统会决定该地址空间在物理内存的实际加载地址，**并将起始地址记录在基址寄存器中**。也就是：

```c
physical address = vritual address + base
```

进程所使用的永远是虚拟地址 `vritual address` ，而硬件则在基址寄存器的基础上加上虚拟地址的数值，进而便可以得到物理地址 `physical address`，随后发给内存系统

**基址寄存器用于确定虚拟地址空间在实际物理地址空间中的起始位置**，而**界限寄存器则用于提供访问保护**。界限寄存器会被设置为一个值，用于表示该地址空间的大小，如果进程的寻址超出该范围或者为负数，则 `CPU` 将触发异常，进程可能被终止

基址与界限寄存器的硬件结构是在芯片中的，每个 `CPU` 一对。我们**将 `CPU` 中**管理内存的部分称为 `MMU, Memory Management Unit`

需要说明的是，界限寄存器有两种使用方式：记录地址空间大小和记录地址空间的结束地址。这两种方式在逻辑上是等价的，但我们之后的叙述以记录空间大小为准

为了支持硬件的动态重定位，我们需要操作系统在关键时刻接入，以实现**基址和界限的虚拟内存**，操作系统职责如下：

* 提供内存管理

在进程创建时，操作系统需要为进程的地址空间找到物理内存空间。由于我们假设进程的地址空间大小相同，因此操作系统可以很容易地找到空闲的物理内存。操作系统可以将整个物理内存看成一个数组，每个位置标记为空闲或已用。每次有新进程创建时便检索该数据结构（通常称为空闲列表 `free list`），为该进程的地址空间分配物理内存

在进程终止时（正常结束或被强制终止），操作系统需要回收该进程占用的物理地址，放回到空闲列表中

* 提供基址和界限管理

在操作系统进行上下文切换时，由于 `CPU` 只有一对基址和界限寄存器。而对于每个进程，这一对寄存器的值必然不相同，这是因为每个进程的地址空间都被加载到不同的物理地址。因此在上下文切换时，操作系统必须**保存基址和界限寄存器**，放到进程结构 `Process structure` 或进程控制块 `Process Control Block` 中。类似的，当操作系统恢复某个进程时也需要从该进程的进程结构或进程控制块中恢复基址和界限寄存器

* 异常处理

操作系统需要提供一些异常处理程序（操作系统会在系统启动时加载这些程序），用来处理内存方面的异常。例如，如果程序试图越界访问，`CPU` 会触发异常，操作系统则需要对该异常进行处理（一般是直接终止进程或者调用异常处理程序）

需要说明的是，地址转换机制完全由硬件完成，操作系统不需要介入。操作系统介入的点主要是上述这三个方面。多数情况是，操作系统设置完硬件后（基址和界限寄存器、进程相关状态），任由程序在 `CPU` 上运行，只有在发生异常时才进行介入

---

## 分段

上面的设计有一个问题，堆和栈之间的内存并没有被进程使用，但还是占用了实际内存。因此简单的使用一对基址界限寄存器实现的虚拟内存很浪费实际的物理内存，并且如果物理内存物理提供连续的空间来放在进程的地址空间，那么该进程也无法运行了。我们需要在此基础上改进，使得虚拟内存的方式能够**支持大地址空间而不会过多的浪费物理内存**

这里我们引入分段 `segmentation` 的概念。我们不再是为整个虚拟地址空间分配一对基址界限寄存器，而是**为虚拟地址空间中的每个逻辑段分配一对基址界限寄存器**。具体地，一个地址空间中通常有三个不同的逻辑段：代码 `code`、栈 `stack`、堆 `heap`。我们在 `MMU` （`CPU` 中管理内存的单元）中引入三对基址界限寄存器，便可以实现分段，如下图：

![Segmentation](../img/Segmentation.png)

一个进程的地址空间不再是完整的全部放入物理内存，而是被分为三个逻辑段，**分别放在物理内存的不同位置**。通过这种方式，我们可以避免将地址空间中堆与栈之间没有被进程使用的内存占用实际的物理内存

那么这便引出了一个问题是，我们该引用哪个段

我们可以取虚拟地址的前几位来对不同的分段进行标识，我们目前目前的分段只有三段，因此我们可以用前两位来进行标识。具体地，我们考虑一个 `14` 位虚拟地址：`0 1 0 0 0 0 1 1 0 1 0 0`

我们将前两位用来标识不同的分段。如果前两位是 `00`，那么表示代码段的地址，对应使用代码段的基址界限寄存器；前两位是 `01` 表示使用堆地址，对应使用堆地址的基址界限寄存器；前两位是 `10` 表示使用栈地址，对应使用栈地址的基址界限寄存器

在这个例子中，该虚拟地址使用的是堆地址，因此用堆地址的基址界限寄存器。剩下的 `12` 位表示**段内偏移**，也就是 `0x68 = 0d104`。**通过将基址寄存器的值与段内偏移相加，硬件便得到了最终的物理地址**（这当然会检测地址是否合法）

如果我们将**单个进程**每个分段的基址和界限放到数组中，为了得到对应的物理地址，硬件会做如下工作：

```c
//get top 2 bits of Vritual address
//SEG_MASK and SEG_SHIFT depend on the number of bits of virtual address
segment = (VritualAddress & SEG_MASK) >> SEG_SHIFT
//Get offset in segmentation
Offset = VritualAddress & OFFSET_MASK
if(Offset >= Bound[segment])
    RaiseException(PROTECTION_FAULT)
else
{
  PhysAddr = Bash[segment] + Offset
  Register = AccressMemory(PhysAddr)
}
```

这种方法被称为显式 `explicit` 方式，直接通过前两位来决定应该使用哪个分段。在隐式 `implicit` 方式中，硬件通过地址产生的方式判断属于哪个段。比如，如果该地址由程序计数器获取得到，那么说明该地址属于代码段；如果从栈指针处得到，那么一定属于栈段；其余的则属于堆段

到此为止我们的地址默认都是向高地址增长，但我们知道栈地址的增长方向是向低地址增长的，也就是反向。只使用基址和界限只能确定物理地址的起始位置和对应分段的大小，**无法判断地址增长的方向**，因此我们还需要额外记录一个量，用于标识该分段的增长方向，如下图：

![GrowsPositive](../img/GrowsPositive.png)

更进一步，如果想要节省内存，不同的进程之间共享地址空间是一个很好的办法。为了支持共享，硬件需要提供额外的支持——保护位 `protection bit`。为每个段增加保护位，用于标识程序是否能够读写该段，以及执行段中的代码。我们可以将代码段标记为只读，那么多个进程便可以共享该代码段，并且还可以保证不会破坏隔离性

由于增加了保护位，因此前面硬件获取地址的代码需要进行修改。具体地，除了要对地址是否合法进行判断外，还需要对保护位进行检测

![ProtectionBit](../img/ProtectionBit.png)

> 物理内存的浪费有两种：外部碎片 `external fragmentation` 和内部碎片 `internal fragmentation`
>
> 当我们将整个地址空间全部放入物理内存时，堆栈之间没有使用的地址空间依旧占用物理内存，这便是**内部碎片**。当我们引入分段时，不同的分段大小会逐渐填充物理内存，导致出现很多小的内存碎片，这便是**外部碎片**
>
> 举个例子就是，当前物理内存中剩下 `5Kb, 10Kb, 15Kb` 的内存碎片，但我们无法将大小为 `20Kb` 的地址空间放入到物理内存中。也就是明明物理内存空间大小足够，但我们无法运行该进程
>
> 空闲空间 `free-space` 管理的算法有很多，在此不过多介绍

---

## 分页

### 原理 & 页表

采取分段实现虚拟内存有一个固有问题是，会导致空间的碎片化 `fragmented`，随着时间的推移将会导致一些原本能够放入物理内存的分段不再能够放入。由于分段大小的不均等性，我们**无法**找到一个算法能够实现**没有**物理内存浪费，因此为了避免掉出现额外的内存开销，我们进一步引入分页 `paging` 的技术

我们不再将进程的地址空间分割成不同的逻辑段，而是分割成**固定大小**的单元，我们称之为**页 `page`** ，同理，我们对物理内存也分割成页大小的单元，我们称每个单元为**页帧 `page frame`**

这么做的好处有两个：一是进程可以在一个页内随意使用地址空间，我们不需要像分段那样额外标记堆栈的增长空间，二是空间空间 `free space` 管理将变得简单，不会出现外部碎片

下图表示一个进程 `64` 位的地址空间，我们将其分割成 `4` 页，每个页的大小为 `16` 字节

![Page1](../img/Page1.png)

我们同样将物理内存分割成页大小的单元，也就是将其分割成 `16` 字节的单元，每个单元称为页帧

![Page2](../img/Page2.png)

可以看到，`page frame 2` 被地址空间 `address space 2`（这里简写 `AS`） 占用，其余点同理。注意到，每个页存放的物理页帧的位置都是不同的，因此有一个很自然的问题是：虚拟页该存放在物理内存的什么位置

**为了记录地址空间中每个虚拟页存放在物理内存的位置**，操作系统为**每个进程**保存一个数据结构，称为页表 `page table`。页表存储每个地址空间中的虚拟页面到物理页帧的转换，每个进程都会有一个页表

我们用一个详细的例子说明页表是如何实现转换的，假设地址空间的大小为 `64` 位，我们考虑如下代码：

```assembly
movl  <vritual address>, %rax
```

该指令从虚拟地址 `virtual address` 读取内存并将其赋值给 `%rax`，我们需要将该进程生成的虚拟地址转换为实际的物理地址，具体做法如下：

我们的地址空间是 `64` 位的，因此我们的虚拟地址为 `6` 位（$2^6=64$），我们将虚拟地址分割成两部分，高位表示虚拟页号 `virtual page number, VPN`，低位表示偏移量 `offset`

我们的地址空间内有四个页，因此 `VPN` 的位数为 `2` 位；每个页的大小为 `16` 字节，偏移量范围为 `[0, 15]` ，因此 `offset` 的位数为 `4` 位。具体分割见下图：

![VAsplit](../img/VAsplit.png)

我们现在得到了虚拟页号 `VPN` 以及虚拟页内的偏移量 `offset`，我们根据上面的页表可以得知，物理帧号 `physical page number, PFN` 为 `7` 的位置存储了虚拟页号 `1`，因此我们便成功地将虚拟地址转换用 `PFN` 的起始地址和偏移量 `offset` 可以表示的物理地址

具体地，假设虚拟地址为 `01 0101`，我们知道这对应的物理帧号为 `7`，也就是起始地址为 `112`，我们加上后面的偏移量 `0101`，得到的物理地址为 `117`

需要额外说明的是，页表可能非常大。比如，一个 `32` 位的地址空间内，假设页的大小为 `4KB`，那么 `32` 位的虚拟地址就会被分为 `20` 位的 `VPN` 和 `12` 位的 `offset`，假设一个页表项 `page table entry, PTE` 的大小为 `4` 字节，那么这就需要 `4MB` 的内存来存储该页表。我们的系统中可以有很多进程同时运行，那么我们需要同时记录它们的页表，这将会是一个非常大的内存开销。目前我们暂且认为页表能够被完整的存储在**内存**中（其实操作系统内存本身都可以虚拟化，因此页表可以存储在操作系统的虚拟化内存中），随后我们会尝试对页表进行优化，降低其内存开销

### 页表内容

页表本质上是一个数据结构，用于记录虚拟页号 `VPN` 到物理帧号 `PFN` 的转换。我们可以将其实现为一个数组，那么操作系统通过 `VPN` 进行索引，找到对应的页表项 `PTE`，从 `PTE` 中提取出对应的 `PFN` 即可

当然， `PTE` 中不止有 `PFN`，，下面我们给出其主要内容：

* 物理帧号 `PFN`
  * 该虚拟页号 `VPN` 对应的物理帧号 `PFN` （`PFN` 的位数需要依据页大小来确定，但一定小于 `32` 或 `64`）
* 有效位 `valid bit`
  * 用于指示该转换地址是否有效。例如，对于一个进程堆栈之间未被使用的页而言，这里的地址转换就是无效的，即对应 `valid bit` 为零
  * 我们可以简单的将这些空间都标记为无效，进而可以不用为这些虚拟页分配物理页帧，从而节省大量的物理内存（需要说明的是，页表本身占的空间不会发生改变，只不过一些虚拟页可以不用分配物理页帧而已）
  * 相应地，如果访问这些页则会陷入操作系统
* 保护位 `protection bit`
  * 表明该页是否可以读取、写入和可执行。相应地，采用不允许的方式访问这些页则会陷入操作系统
* 存在位 `present bit`
  * 表示该页是在物理内存中还是在磁盘上，我们在讨论交换 `swap` 时会涉及到该位
* 脏位 `dirty bit`
  * 表示该页面被带入内存后是否被修改
* 参考位 `reference bit` 也被称为访问位 `access bit`
  * 用于追踪页是否被访问，也用于确定哪些页访问的次数多，这在讨论页面替换 `page replacement` 时会涉及到

### 分页速度

我们知道的是分页所需要的空间十分的大，我们将会在后面对页表的实现进行优化，在此我们讨论分页在速度方面的影响

我们还是分析上面的例子，考察硬件需要对一个虚拟地址所做哪些转换操作

```assembly
movl  21, %rax
```

硬件为了将虚拟地址 `21` 转换为正确的物理地址 `117`，需要先从进程的页表中提取适当的 `PTE`，然后找到对应的 `PFN`

硬件需要知道当前进程页表的位置，我们假定有一个页表基址寄存器 `page-table base register` 存储页表的起始地址，那么硬件将会做如下工作：

```c
//get page-table entry address
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))//PageTableBaseRegister = PTBR

//fetch the PTE
PTE = AccessMemory(PTEAddr)//PTE must access memory

//check if process can access the page
if(PTE.valid == false) RaiseException(SEGMATATION_FAULT)
else if(CanAccess(PTE.ProtectBits) == false) RaiseException(PROTECTION_FAULT)
else
{
    //get physical address
    offset = VirtualAddress & OFFSET_MASK
    PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
    Register = AccessMemory(PhysAddr)
}
```

观察上面的代码可以发现，我们只是对虚拟内存进行了一次访问，但实际上我们**执行了两次的物理内存访问**。第一次是用于从物理内存中读取 `PTE`，第二次是基于 `PTE` 得到 `PFN`

也就是说，我们每对虚拟内存访问一次，实际上都会有两次对物理内存的访问。考虑下面的一个循环：

```c
for(int i = 0; i < 1000; i ++)
    a[i] = 0;
```

这个循环执行了 `1000` 次，看上去我们只是访问了 `1000` 次的虚拟地址（如果可以，我们希望能对应访问 `1000` 次物理地址），但实际上硬件在进行分页的地址转换时，访问了 `2000` 次的物理地址，这个开销实在是太大了

分页的好处有很多。首先它不会导致出现外部碎片，这是因为虚拟页和物理页帧的大小是一样的，因此不会造成浪费。其次，它是否的灵活，不仅支持稀疏的地址空间（没有用到的页面我们不需要存储），还不需要标注内存增长方向

但为了实现分页而导致页表过大的内存开销以及分页机制本身的速度过慢，都是分页的问题，下面我们着手解决这两个问题

---

## Translation-lookaside buffer (TLB)

我们将物理内存和地址空间都分割成固定大小的单元（页帧和页），而为了记录二者的对应关系，衍生出了页表。由于页表存储在物理内存中，这导致在虚拟地址转换为物理地址时，**额外执行了一次内存访问**，我们需要尽可能避免额外的内存访问这个问题

具体做法为，我们在硬件上新添加一个转换旁路缓存区 `translation-lookaside buffer, TLB`，本质上是频繁发生的虚拟地址到物理地址的**地址转换缓存** `address-translation cache`。在每次内存访问时，首先检查 `TLB`，如果其中有转换映射，则将其取出（此时转换很快），不需要访问页表；如果没有，则访问页表找到对应的转换映射，将其插入 `TLB`

`TLB` 带来巨大的性能提升，本质上是基于局部性 `locality` 这一原理。局部性分为时间局部性 `temporal locality` 和空间局部性 `spatial locality`。前者是指程序倾向于访问最近访问过的元素，也可以说是对元素进行重复访问；后者是指程序倾向于访问临近的元素，内存地址上的临近

### TLB Basic Algorithm

我们假定页表为简单的线性数组，因此我们的 `TLB` 描述算法如下：

```c
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TLBEntry) = TLB_Lookup(VPN)
if(Success == true)//TLB hit
{
    if(CanAccess(TLBEntry.ProtectionBits) == true)
    {
        offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TLBEnty.PFN << SHIFT) | offset
        AccessMemory(PhysAddr)
    }
}
else//TLB miss
{
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccressMemory(PTEAddr)
    if(PTE.valid == false) 
        RaiseException(SEGMATATION_FAULT)
    else if(CanAccess(PTE.ProtectBits) == false) 
        RaiseException(PROTECTION_FAULT)
    else
    {
        TLB_Insert(VPN, PTN.PFN, PTE.ProtectionBits)
        RetryInstruction()
    }
}
```

算法大致流程如下：

* 首先从虚拟地址中取出虚拟页号 `VPN`，随后检查 `TLB` 是否有该虚拟页号的地址映射
* 如果 `TLB` 中存在地址映射 `TLB hit`，那么直接从 `TLB` 表项中取出，对保护位进行检查后取出偏移量 `offset`，进而直接访问物理内存。整个访问虚拟地址的过程**没有额外的内存访问**，一次虚拟地址访问对应一次物理地址访问
* 如果 `TLB` 中不存在地址映射 `TLB miss`，硬件会访问页表，找出该转换映射，这里与上面没有引入 `TLB` 的逻辑一样。不同的是我们将 `TLB` 更新完成后，会**重新尝试执行该指令**，而不是在此直接进行内存访问

我们来看一个 `TLB` 实际处理的例子，这可以很好的展示 `TLB` 对分页速度的优化

我们假设有一个 `8` 位的虚拟地址空间，一个页 `page` 的大小为 `16` 字节。因此 `8` 位的虚拟地址的前四位用于表示 `VPN`，后四位用于表示 `offset`。有一个 `10` 个元素的 `int` 数组，起始虚拟地址为 `100`，具体如下图所示：

![TLBsample](../img/TLBsample.png)

当我们执行一个循环：

```c
for(int i = 0; i < 10; i ++)
    a[i] = 0;
```

简单起见，我们只考虑对数组的内存访问。当访问第一个虚拟地址时 `100`（`a[0]`），此时硬件检查 `TLB`，此时 `TLB miss`，因此硬件将会加载这一页的地址映射到 `TLB` 中

当访问后面的 `104, 108`（`a[1], a[2]`），均为 `TLB hit`，以此类推，当访问 `a[3]` 和 `a[7]` 时发生 `TLB miss`，而访问 `a[4], a[5], a[6], a[8], a[9]` 时均为 `TLB hit`

总体来看，我们执行了 `10` 次内存访问，`TLB` 未命中的次数只有三次，也就是我们一共执行了 `13` 次物理内存访问，这个效率是巨大的提升

需要说明的是，如果页的大小更大（典型的页大小一般为 `4KB`），那么 `TLB` 的效果将会更好。如果程序满足 `temporal locality`，在不久的将来从新访问该数组，那么将不会有额外的物理内存访问